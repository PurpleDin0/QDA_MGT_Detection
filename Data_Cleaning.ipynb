{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thesis_data_Cleaining_Ales.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Brl6YFzlglTC"
      ],
      "authorship_tag": "ABX9TyOyYfJzGX80Yz72JpxB0mbc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PurpleDin0/QDA_NLG_Detection/blob/master/Data_Cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V0VCiD7hPRdp"
      },
      "source": [
        "# Collect and prep data for analysis\n",
        "\n",
        "Contact info: Barney.Ales@gmail.com\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ciq_sfs9izzH"
      },
      "source": [
        "#Introduction\n",
        "This is the start of a multi-step process to analyze the capabilites of Natural Language Generation (NLG) models.  Work was split into three python notebooks in order to provide credit to code written by others, simplify future analysis, and maximize possible code re-use by others.  All notebooks are publicly availible and posted to [my Github](https://github.com/PurpleDin0/QDA_NLG_Detection), with the training data I used.  <font color=yellow> The trained model is ~500 MB in size.  This is too large of a file for GitHub so it is located in google drive here**(insert link to final google drive resting location)**.</font>\n",
        "\n",
        "1.   [Data_Cleaning.ipynb](https://github.com/PurpleDin0/QDA_NLG_Detection/blob/master/Data_Cleaning.ipynb) (This notebook)\n",
        "  0.   Explain the project\n",
        "  1.   Import data\n",
        "  2.   Perform Basic data cleaning\n",
        "  3.   Train the Markovify model\n",
        "  4.   Generate text with the trained Markovify Model\n",
        "2.  [\"Train a GPT-2 Text-Generating Model w/ GPU.ipynb\"](https://github.com/PurpleDin0/QDA_NLG_Detection/blob/master/Train%20a%20GPT-2%20Text-Generating%20Model%20w_%20GPU.ipynb)\n",
        "  1. Fine-tune 124M-parameter version of GPT-2\n",
        "  2. Save fine-tuned model\n",
        "  3. Generate text with the trained model \n",
        "3. [Thesis_Analysis.ipynb](https://github.com/PurpleDin0/QDA_NLG_Detection/blob/master/Analysis.ipynb)\n",
        "  1. Load generated data\n",
        "  2. Generate Analyze data\n",
        "  3. Graph results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Brl6YFzlglTC"
      },
      "source": [
        "##Research Question & Hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8WlMt6Q-g4Nm"
      },
      "source": [
        "**Research Question**  \n",
        "Can machine-generated text be detected through quantitative evaluation of centering resonance analysis (CRA) networks?  \n",
        "**Hypothesis**  \n",
        "Machine-generated text created using Natural Language Generation (NLG) systems will be more discursively similar to other samples of machine-generated text by a statistically significant degree than to comparable human-created text content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PVhzml7kSGpI"
      },
      "source": [
        "#First load all the relevant libraries\n",
        "---\n",
        "* [pandas](https://pandas.pydata.org/): used to read in CSV data, do basic data cleaning, and store all our data.  This is a heavy hitter of Python for Data Science.\n",
        "* [Markovify](https://datascienceplus.com/natural-language-generation-with-markovify-in-python/): used to build markov chain generator, link is to instructions.  Here is the [Github link](https://github.com/jsvine/markovify)\n",
        "* [Pickle](https://docs.python.org/3/library/pickle.html): Used to save variables for later use\n",
        "* [JSON](https://docs.python.org/3/library/json.html): Used to save data to files for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_8FQc5vzSEGw",
        "outputId": "1e51dd0b-fd9d-46a6-8816-1e20183ac359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "#markovify needs to be installed as it isn't a baseline python module\n",
        "!pip install markovify \n",
        "\n",
        "#clone the GitHub repo with all the training data.\n",
        "!git clone https://github.com/PurpleDin0/QDA_NLG_Detection.git \n",
        "\n",
        "# navigate to the created folder\n",
        "%cd /content/Quantitative-Discursive-Analysis/ \n",
        "\n",
        "import pandas as pd #Pandas, so we can do lots of cool data science stuff\n",
        "print(\"Pandas imported as Version: \",pd.__version__)\n",
        "import markovify #Markov Chain Generator, train and generate an NLG model\n",
        "print(\"Markovify imported as Version: \", markovify.__version__)\n",
        "import pickle #So we can save any of our output variables for later use\n",
        "import json #So we can save any of our output items for later use"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting markovify\n",
            "  Downloading https://files.pythonhosted.org/packages/de/c3/2e017f687e47e88eb9d8adf970527e2299fb566eba62112c2851ebb7ab93/markovify-0.8.0.tar.gz\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 11.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: markovify\n",
            "  Building wheel for markovify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markovify: filename=markovify-0.8.0-cp36-none-any.whl size=10694 sha256=af6345a0af2ff28bfb4ad1a80a07d78011a0b3c858614305a844e9bce2842fc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/a8/92/35e2df870ff15a65657679dca105d190ec3c854a9f75435e40\n",
            "Successfully built markovify\n",
            "Installing collected packages: unidecode, markovify\n",
            "Successfully installed markovify-0.8.0 unidecode-1.1.1\n",
            "Pandas imported as Version:  1.0.3\n",
            "Markovify imported as Version:  0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tHxZ2wfaPgFv"
      },
      "source": [
        "# Import your data \n",
        "First you need to get a CSV loaded with data that you want to retrain your GPT-2 model and train your Markovify model.  I used English Language state controlled media for my training/fine tuning data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mXNdGVJMQswS"
      },
      "source": [
        "Upload your csv file to your google drive folder my file is named \"English_Language-State_Media-10_15_to_11_15-2019.csv\", and is stored at \"/content/QDA_NLG_Detection/Data'.\n",
        "This is in the repo we cloned from GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XXt98kpURWtF"
      },
      "source": [
        "Next navigate to the folder you stored your file.  My file is stored -> /content/drive/My Drive/Colab Notebooks/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ol-j0LqhRmPJ",
        "outputId": "26455734-6433-4ecb-d7fe-89897b6b9943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "%cd /content/Quantitative-Discursive-Analysis/Data/\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n",
            " \u001b[0m\u001b[01;34mcheckpoint\u001b[0m/                                gpt_sputnik_text_data_5.json\n",
            "'Copy of bookworm.ipynb'                    gpt_sputnik_text_data_6.json\n",
            "'Copy of MST698S_CNN-exercise.ipynb'        markovify_text_stored.json\n",
            "'Copy of sentiment_analysis.ipynb'         'Monday_Makeover (1).ipynb'\n",
            "'Copy of text_processing.ipynb'             Monday_Makeover.ipynb\n",
            " \u001b[01;34mCoursework\u001b[0m/                                mutliprocessing_test.ipynb\n",
            " covid_19_test.ipynb                        NLP_Udacity.ipynb\n",
            " English_Language-State_Media-11-2019.csv   Research_Notes.ipynb\n",
            " gpt_sputnik_text_data_1.json               Sputnik_body_alltext.p\n",
            " gpt_sputnik_text_data_2.json               \u001b[01;34mThesis\u001b[0m/\n",
            " gpt_sputnik_text_data_3.json               Thesis_Analysis-ALES.ipynb\n",
            " gpt_sputnik_text_data_4.json               Untitled0.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X1jIuJjFSyS8"
      },
      "source": [
        "Data in `English_Language-State_Media-10_15_to_11_15-2019.csv` was collected and exported from an online news aggregation site. \n",
        "\n",
        "- [x] Import raw news data export (English_Language-State_Media-10_15_to_11_15-2019.csv)\n",
        "- [x] Display the basic information about the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CTQq1JQYRukK",
        "outputId": "7a38969d-6423-4eca-c312-714d3b5c20c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "data = pd.read_csv('English_Language-State_Media-10_15_to_11_15-2019.csv') #imports the file\n",
        "data.columns = data.columns.str.replace(' ', '_') #cleans up the columns by replacing spaces with \"_\" - Note: Spaces are evil and their use in code is immoral :-P\n",
        "#data.head() #This displays the first few rows of the data\n",
        "data = data.drop(columns=['Unnamed:_0']) #drop the old index from the csv file\n",
        "data.info() #This displays info on the data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28845 entries, 0 to 28844\n",
            "Data columns (total 7 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   Title               28845 non-null  object\n",
            " 1   Body                28793 non-null  object\n",
            " 2   Source_Name         28845 non-null  object\n",
            " 3   Source_Date,_Start  28845 non-null  object\n",
            " 4   Creator             20224 non-null  object\n",
            " 5   Keywords            4541 non-null   object\n",
            " 6   Source_Medium       28845 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 1.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zikI2d-4fJf9"
      },
      "source": [
        "##Show some more info on the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ORPcB0HeV98",
        "outputId": "a9ce07bb-df91-4e90-e83e-577e69cf2708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#show the datafram\n",
        "data.Creator"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                   RT\n",
              "1        Lucas Jackson\n",
              "2                   RT\n",
              "3                   RT\n",
              "4                   RT\n",
              "             ...      \n",
              "28840              NaN\n",
              "28841              NaN\n",
              "28842              NaN\n",
              "28843              NaN\n",
              "28844              NaN\n",
              "Name: Creator, Length: 28845, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_CHHEA4RZpWA",
        "outputId": "5134f46b-93bd-4a8d-8e0e-5f68e471dbfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#show information on each column\n",
        "for column in data.columns.values: \n",
        "  print(data[column].value_counts())\n",
        "  print('\\n\\n')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xinhua photos of the day                                                              30\n",
            "China-related news briefing                                                           25\n",
            "What's trending worldwide                                                             21\n",
            "[UNABLE TO COLLECT DUE TO SITE ERROR]                                                 12\n",
            "Chinese shares close lower Wednesday                                                   8\n",
            "                                                                                      ..\n",
            "Nankai University celebrates 100th anniversary with glory from past and for future     1\n",
            "Babysitter is Not Amused: Cat Teaches Corgi Puppies Good Manners                       1\n",
            "Haiti's opposition rejects dialogue proposed by Washington                             1\n",
            "White Cane Safety Day event held in Beirut, Lebanon                                    1\n",
            "Trump attacks Dems, 'LameStream' media as impeachment nears public phase               1\n",
            "Name: Title, Length: 25760, dtype: int64\n",
            "\n",
            "\n",
            "\n",
            "当前浏览器不能支持视频播放，可下载最新的QQ浏览器或者安装FLASH即可播放                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               108\n",
            "(Source: CGTN)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        87\n",
            "(Source: Xinhua)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      45\n",
            "News updates of all the most important events in the world, written and produced in the Global South, with fresh perspectives from our international team of correspondents.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           9\n",
            "Most Viewed in 24 Hours\\n\\nState Council News\\n\\nPremier: Govt to keep tight budget\\n\\nQuick view: State Council executive meeting on Oct 16\\n\\nTop 10\\n\\nChina's internet achievements for the past 25 years\\n\\nEditor's picks\\n\\nChina's richest women named in annual list\\n\\nChina's patent applications hit record in 2018\\n\\nChina Data\\n\\nUnprecedented growth\\n\\nQ&amp;A With CEO\\n\\nAI offers key to digital transformation\\n\\nA smart approach to digital transformation\\n\\nSpecial\\n\\n2019 WIC\\n\\nChina US trade tensions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   9\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ... \n",
            "A visitor (C) experiences Honda Walking Assist device at the Automobile exhibition area during the second China International Import Expo (CIIE) in Shanghai, east China, Nov. 10, 2019. The second CIIE was held from Nov. 5 to Nov. 10 at the National Exhibition and Convention Center in Shanghai. (Xinhua/Wang Peng)\\n\\n1 2 3 4 5 6 7 8 9 10 Next   &gt;&gt;|\\n\\n|&gt;|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1\n",
            "The Lhasa-Nyingchi highway has helped lift local people out of poverty in Basomtso, a place rich in tourism resources in southwest China's Tibet Autonomous Region.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1\n",
            "A bridge stretches across the Fenhe River in Taiyuan, capital city of Shanxi province. [Photo provided to China Daily]\\n\\nChina is speeding up efforts to establish the national territory spatial planning system by 2020, with ecological protection being the priority among the three \"red lines\" that guide the construction.\\n\\nIn May, the Communist Party of China Central Committee and the State Council released guidelines on the planning system and the supervision of its implementation.\\n\\nEarly this month, the State Council released opinions on implementation of the three red lines, helping to guide the building of the system that is expected to bring about more efficient and eco-friendly development.\\n\\nThe red line for ecological protection-a key government strategy putting designated areas under mandatory protection-is listed at the top. The other red lines are for the designation of permanent farmland and for an urban and rural development plan.\\n\\nThe ecological red line is to guarantee the safety of areas that are crucial to the protection of water sources, biodiversity, water and land maintenance and coastal safety, as well as wind control and sand fixation.\\n\\nOther regions that may have important ecological value will also be protected under the red line.\\n\\nAccording to the opinions, areas being protected by the ecological red line will be composed of two parts-core protected areas, where all human activities are prohibited, and normal protected areas that only allow nine human activities, including archaeological efforts, limited eco-friendly tours and infrastructure construction for water supply and disaster prevention.\\n\\nThe red line for permanent farmland designation aims to ensure farmland safety, improve farmland quality and prevent farmland from being used for other purposes.\\n\\nLastly, the red line for urban and rural development will have an overall consideration for the local population and economic distribution, giving a long-term picture of sustainable development in both rural and urban areas.\\n\\n\"The opinions focused on eco-civilization and being people-oriented,\" said Liu Guohong, head of the National Territorial Spatial Planning Bureau under the Ministry of Natural Resources. \"They also emphasized that development should give way to eco-protection, which shows the government's great determination to protect nature.\"\\n\\nThe third national land survey, which was launched in 2017 by the State Council, will serve as a crucial support to the national territorial spatial planning work, according to Zhang Bing, deputy director of the bureau.\\n\\nThe survey, which is ongoing, will cover all land in China. It will thoroughly evaluate the status quo of the country's land use and collect accurate land data.\\n\\nSurvey items include cataloging the use of land resources, ownership and natural and economic conditions.\\n\\nBy 2035, China is expected to see highly efficient usage of land and water resources, which will significantly raise people's living standards and contribute to sustainable green development.      1\n",
            "Motorcyclists ride on the Sheikh Jaber Al-Ahmad Al-Sabah Causeway in Kuwait City, Kuwait, Nov. 1, 2019. (Photo by Asad/Xinhua)\\n\\n1 2 3 4 Next\\n\\n1 2 3 4 Next                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1\n",
            "VALLETTA, Oct. 28 (Xinhua) -- Migrants at Malta's Hal Safi Detention Center were arrested on Monday, after the riot police were called in during a protest at the center.\\n\\nHolding banners protesting over their detention, the migrants insisted they are not criminals. Police were called in when migrants allegedly threw objects at the detention service staff.\\n\\nAccording to an online story by newspaper Malta Today, there has been no official statement on the exact number of arrests made. A police spokesperson said nobody was injured.\\n\\nMigrants are held in detention pending identification. They have been protesting the length of time that the authorities are taking to release them, saying that their rights have been breached.\\n\\nProtests demanding freedom have been held since September. Last week a riot occurred at Malta Hal Far open center, during which 107 migrants were arrested.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1\n",
            "Name: Body, Length: 28428, dtype: int64\n",
            "\n",
            "\n",
            "\n",
            "Xinhua                                 12765\n",
            "Sputnik                                 4320\n",
            "China Daily Online (Global Edition)     3423\n",
            "Global Times Online                     1981\n",
            "RT Online                               1828\n",
            "Fars News Agency                        1427\n",
            "Prensa Latina                            875\n",
            "Tasnim                                   798\n",
            "Press TV                                 631\n",
            "Telesur Online                           527\n",
            "Cuban News Agency                        216\n",
            "Granma Online                             54\n",
            "Name: Source_Name, dtype: int64\n",
            "\n",
            "\n",
            "\n",
            "2019-11-07T00:00:00Z    65\n",
            "2019-11-05T00:00:00Z    49\n",
            "2019-11-01T00:00:00Z    47\n",
            "2019-10-24T00:00:00Z    47\n",
            "2019-10-18T00:00:00Z    44\n",
            "                        ..\n",
            "2019-11-04T18:33:55Z     1\n",
            "2019-11-13T17:19:06Z     1\n",
            "2019-10-20T22:12:36Z     1\n",
            "2019-11-04T20:18:39Z     1\n",
            "2019-11-15T12:11:19Z     1\n",
            "Name: Source_Date,_Start, Length: 26608, dtype: int64\n",
            "\n",
            "\n",
            "\n",
            "RT                                               1619\n",
            "FarsNews Agency                                  1374\n",
            "Xinhua                                            519\n",
            "AFP                                               393\n",
            "Global Times                                      346\n",
            "                                                 ... \n",
            "David Bartosch                                      1\n",
            "Xinhua – Global Times - Global Times - Xinhua       1\n",
            "Ehizuelen Michael Mitchell Omoruyi                  1\n",
            "Han Junhong in Changchun and Zhou Huiying           1\n",
            "Ian Goodrum                                         1\n",
            "Name: Creator, Length: 2815, dtype: int64\n",
            "\n",
            "\n",
            "\n",
            "grabación, programa completo, sin comerciales, telesur, tv                     16\n",
            "None                                                                           10\n",
            "video | golden retriever                                                        3\n",
            "Dog | puppy | golden retriever                                                  3\n",
            "summit | Africa | Russia                                                        3\n",
            "                                                                               ..\n",
            "tensions | farmer | Palestinian Authority | Gaza | Israel                       1\n",
            "incident | F-35 | war games | HMS Queen Elizabeth | United States | Britain     1\n",
            "Economy | New Delhi | India                                                     1\n",
            "k-wave | k-pop | EXO | South Korea                                              1\n",
            "mine blast | mine | Explosion | Germany                                         1\n",
            "Name: Keywords, Length: 4485, dtype: int64\n",
            "\n",
            "\n",
            "\n",
            "Internet       24546\n",
            "INTERNET        2348\n",
            "PUBLICATION     1374\n",
            "NEWS AGENCY      577\n",
            "Name: Source_Medium, dtype: int64\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RgK3OAH9UQ8h"
      },
      "source": [
        "# Perform basic data cleaning/prep#\n",
        "The above info tells us that the data has 28,793 articles, but there is some weirdness to the values.  The quantity of body items is less then the quantity of title items, this generally means that some of the values are null (stored as NaN), but we don't want this so we will replace those NaN values with an empty text string \"\".   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LK0LSkNQZBuz",
        "outputId": "40dbc7ae-f90e-4546-ab7f-05e1f299e8c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "values = {'Body': \"\"} #create a dictionary with the columns that you want to search and the value you want to replace.\n",
        "data = data.fillna(value=values) #Some of the body field is blank\n",
        "data.info() #display the info to see if we fixed it"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28845 entries, 0 to 28844\n",
            "Data columns (total 7 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   Title               28845 non-null  object\n",
            " 1   Body                28845 non-null  object\n",
            " 2   Source_Name         28845 non-null  object\n",
            " 3   Source_Date,_Start  28845 non-null  object\n",
            " 4   Creator             20224 non-null  object\n",
            " 5   Keywords            4541 non-null   object\n",
            " 6   Source_Medium       28845 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 1.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qxTU7g7oTNmq",
        "outputId": "31aae4b4-3960-43a3-a61a-21d83620cd5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(data.Source_Name.value_counts()) #Prints a count of the number of entries for each of the unique sources"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xinhua                                 12765\n",
            "Sputnik                                 4320\n",
            "China Daily Online (Global Edition)     3423\n",
            "Global Times Online                     1981\n",
            "RT Online                               1828\n",
            "Fars News Agency                        1427\n",
            "Prensa Latina                            875\n",
            "Tasnim                                   798\n",
            "Press TV                                 631\n",
            "Telesur Online                           527\n",
            "Cuban News Agency                        216\n",
            "Granma Online                             54\n",
            "Name: Source_Name, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YMwFgTQAvcBx"
      },
      "source": [
        "That is alot of news articles and I want to \"write\" articles in the style of this media, but I do not have the time to read all those so lets do some data science! \n",
        "\n",
        "First we will parse out the sputnik news articles and store all the text as one long string.  We will start each article \"\\<START_TEXT\\>\" and end with \"\\<END_TEXT\\>\", for easy future parsing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O9ytvHqg9279",
        "outputId": "26ddc343-dea4-4dcc-e8f4-84a9905ed9d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "source_selection = 'Sputnik' #starting with Sputnik as a text case, if this works the code can be modified to do this for each source\n",
        "selected_data = data.loc[data['Source_Name'] == source_selection]\n",
        "body_alltext = \"\"\n",
        "for index, row in selected_data.iterrows(): #Note: iterating over a dataframe is strongly not reccomended\n",
        "    body_alltext += \"<START_TEXT>\" \n",
        "    body_alltext += row['Body']\n",
        "    body_alltext += \"<END_TEXT>\" \n",
        "    #body_alltext += \"\\n\\n\" \n",
        "    \n",
        "#check to see how if all the articles where input correctly\n",
        "if data.Source_Name.value_counts()['Sputnik'] == body_alltext.count('<END_TEXT>'): \n",
        "    print(f\"number of articles combined is: {body_alltext.count('<END_TEXT>')}\")\n",
        "else:\n",
        "    print(f\"Something went wrong, we combined {body_alltext.count('<END_TEXT>')} out of {data.Source_Name.value_counts()['Sputnik']} articles\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of articles combined is: 4320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0XU1vtFJ-xa3"
      },
      "source": [
        "Dump the output text to a a csv and a pickle file for future use.  Both where used to simplify future access."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C0QWwFJWNmSK",
        "outputId": "bd010250-744c-43ea-cf1a-7274470e51a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "selected_data['Body'].to_csv('Sputnik_body_alltext.csv', index=False)  #save the parsed data to a csv file"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning:\n",
            "\n",
            "The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CYtuCarX-yA-",
        "colab": {}
      },
      "source": [
        "pickle.dump( body_alltext, open( \"Sputnik_body_alltext.p\", \"wb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7L2-sWm6-hm4"
      },
      "source": [
        "# Train the Markovify Model\n",
        "Now lets train a markovify model with the Sputnik text to make a russian news bot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TF-S8NARYUqo"
      },
      "source": [
        "First we will load the data from the pickle file we saved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TpCDEH99YSgL",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/'My Drive'/'Colab Notebooks'\n",
        "body_alltext = pickle.load( open( \"Sputnik_body_alltext.p\", \"rb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z2u3Bq489p6r",
        "colab": {}
      },
      "source": [
        "sputnik_model = markovify.Text(body_alltext)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qEYJ8OJuWf6_"
      },
      "source": [
        "#Generate text with the trained Markovify model \n",
        "Now lets generate some news"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S926Tj8E6v12",
        "outputId": "ab234565-8d97-4bb6-c0f3-9d26363ff096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "markovify_text_stored = []\n",
        "for i in range(0, 12500):\n",
        "    markovify_text_stored.append(sputnik_model.make_sentence())\n",
        "\n",
        "%cd /content/drive/'My Drive'/'Colab Notebooks'\n",
        "with open('markovify_text_stored.json', 'w', encoding='utf-8') as f:\n",
        "   json.dump(markovify_text_stored, f, ensure_ascii=False, indent=4)\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n",
            "\u001b[0m\u001b[01;34m'698R - Data Science Math'\u001b[0m/\n",
            " \u001b[01;34mcheckpoint\u001b[0m/\n",
            "'Copy of Train a GPT-2 Text-Generating Model w  GPU'\n",
            " English_Language-State_Controlled_Media-11-2019.csv\n",
            " markovify_text_stored.json\n",
            " \u001b[01;34mMST698O-Intro_Data_Science\u001b[0m/\n",
            " \u001b[01;34mMST698R-Data_Science_Math\u001b[0m/\n",
            " MST-698R_Project_Ales.ipynb\n",
            " Research_Notes.ipynb\n",
            " Sputnik_body_alltext.p\n",
            " \u001b[01;34mThesis\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FrWvNtJ1CYcM",
        "outputId": "9ac726c9-2ad3-4e1f-9eb1-969508cfbfc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "#Open the data we generated with markovify\n",
        "with open(\"markovify_text_stored.json\", \"r\") as markovify_read_file: \n",
        "    markovify_text_data = json.load(markovify_read_file)\n",
        "print(\"example Markovify content:\\n\")\n",
        "for n in range(70, 80):\n",
        "    print(markovify_text_data[n])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example Markovify content:\n",
            "\n",
            "The material which purports to support inclusiveness had been downloaded to a man - allegedly the murderous regime of Nicolas Dupont-Aignan, the Belgian People's Party described the US has been confined to a statement by Saudi Crown Prince Mohammed bin Zayed Al Nahyan, and the manner in the Southeast Asian nations with many mocking the people outside the Swedish parliament in Stockholm in 2018.\n",
            "Mexico, where he was forced to ask Drake for clarification.\n",
            "Are women equally as capable of carrying out a simulated bombing of Nagasaki the only way tackle this problem seriously and Misawa has suspended diplomatic, trade and diplomatic row for several years.\n",
            "According to the global office of Prime Minister Imran Khan should be free of charge, if they had registered 4,628 complaints, of which DC is a man was rescued from a standard precautionary measure due to the oilfields area.\n",
            "Gwadar Master Plan was also taken to prison reform, and drafting immigration policy.\n",
            "“In response to a broader agenda to enhance maritime security.\n",
            "Earlier, MPs passed a special ingredient – marijuana, as the cyclone weakened, local authorities Millions of people in Pakistan-administered Kashmir as part of George W. Bush as a threat to the report.\n",
            "Pressure is on display at Sotheby's auction rooms in the grips of an internal government review, which could open the possibility of redeploying some of the ‘investigation’ and prosecution” of Flynn.\n",
            "Last week, she even thought about choosing a different dynamic in each bus, with just under 20 percent contained as of today.\n",
            "Emersberger pointed out, Malaysia has recently announced that his office not as hot as his anti-Americanism and poor weather conditions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JEdQNTRZ88iY"
      },
      "source": [
        "Awesome, now we have a trained Markov Model. However, as you can see even though the system generates mostly grammatically correct sentences, they are incoherent when joined together.\n",
        "So, lets build a system that can generate long coherent sentences. [Enter the GPT-2 fine tuning Notebook](https://colab.research.google.com/drive/1Hs30ZifOvO6T4WSDVWS7H7LaxFmzv-ER#scrollTo=4RNY6RBI9LmL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "45rFjB93ffFj"
      },
      "source": [
        "# License Information\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2020 Barney Ales\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}