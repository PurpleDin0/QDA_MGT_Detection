{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7LoMj4GA4n_"
   },
   "source": [
    "#  Train a GPT-2 Text-Generating Model w/ GPU For Free \n",
    "\n",
    "by [Max Woolf](http://minimaxir.com) - (very minor modifications by Barney Ales)  [Click here for Max Woolf's orignal Colab Notebook.](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce)\n",
    "\n",
    "*Last updated: 12 Feb 2020*\n",
    "\n",
    "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n",
    "\n",
    "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read my [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n",
    "\n",
    "\n",
    "To get started:\n",
    "\n",
    "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
    "2. Make sure you're running the notebook in Google Chrome.\n",
    "3. Run the cells below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11543,
     "status": "ok",
     "timestamp": 1587853547471,
     "user": {
      "displayName": "Barney Ales",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg86EIDEUXFuwIBLZfymbGYfGk1mnezArvKefKW=s64",
      "userId": "06512472277656029571"
     },
     "user_tz": 240
    },
    "id": "KBkpRgBCBS2_",
    "outputId": "625dd7e4-b240-4a47-99bc-8ca0404776a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n",
      "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "!pip install -q gpt-2-simple\n",
    "import gpt_2_simple as gpt2\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from google.colab import files\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8KXuKWzQSsN"
   },
   "source": [
    "## Mounting Google Drive\n",
    "\n",
    "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
    "\n",
    "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KIQaiUfdB93M"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bj2IJLHP3KwE"
   },
   "source": [
    "## GPU\n",
    "\n",
    "Colaboratory uses either Nvidia T4 GPU, Nvidia P100 GPU, or an Nvidia K80 GPU. The T4 and P100 are slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
    "\n",
    "You can verify which GPU is active by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1512,
     "status": "ok",
     "timestamp": 1587853574352,
     "user": {
      "displayName": "Barney Ales",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg86EIDEUXFuwIBLZfymbGYfGk1mnezArvKefKW=s64",
      "userId": "06512472277656029571"
     },
     "user_tz": 240
    },
    "id": "sUmTooTW3osf",
    "outputId": "91d8d417-b147-4a3a-ae54-017df8488fd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 25 22:26:15 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "Your runtime has 27.4 gigabytes of available RAM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "\n",
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('\\nYour runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wXB05bPDYxS"
   },
   "source": [
    "## Downloading GPT-2\n",
    "\n",
    "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
    "\n",
    "There are three released sizes of GPT-2:\n",
    "\n",
    "* `124M` (default): the \"small\" model, 500MB on disk.\n",
    "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
    "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
    "* `1558M`: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
    "\n",
    "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
    "\n",
    "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
    "\n",
    "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2401,
     "status": "ok",
     "timestamp": 1587853614339,
     "user": {
      "displayName": "Barney Ales",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg86EIDEUXFuwIBLZfymbGYfGk1mnezArvKefKW=s64",
      "userId": "06512472277656029571"
     },
     "user_tz": 240
    },
    "id": "P8wSlgXoDPCR",
    "outputId": "79766bf7-b765-4e58-e3b9-2206feb9f794"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 933Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 153Mit/s]                                                    \n",
      "Fetching hparams.json: 1.05Mit [00:00, 1.14Git/s]                                                   \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:01, 256Mit/s]                                   \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 538Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 211Mit/s]                                                 \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 227Mit/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "gpt2.download_gpt2(model_name=\"124M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BT__brhBCvJu"
   },
   "source": [
    "## Uploading a Text File to be Trained to Colaboratory\n",
    "\n",
    "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
    "\n",
    "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
    "\n",
    "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6OFnPCLADfll"
   },
   "outputs": [],
   "source": [
    "file_name = \"Sputnik_body_alltext.txt\" #this is a ~2 million word text file that contains 1 month of Sputnik news articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HeeSKtNWUedE"
   },
   "source": [
    "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Z6okFD8VKtS"
   },
   "outputs": [],
   "source": [
    "gpt2.copy_file_from_gdrive(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LdpZQXknFNY3"
   },
   "source": [
    "## Finetune GPT-2\n",
    "\n",
    "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
    "\n",
    "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
    "\n",
    "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
    "\n",
    "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
    "\n",
    "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
    "\n",
    "\n",
    "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
    "* **`sample_every`**: Number of steps to print example output\n",
    "* **`print_every`**: Number of steps to print training progress.\n",
    "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
    "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
    "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2439575,
     "status": "ok",
     "timestamp": 1581123122497,
     "user": {
      "displayName": "Barney Ales",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDMQ8dxB0YgPuHrb8rHWGEB249MalarcY7DpcE2=s64",
      "userId": "06512472277656029571"
     },
     "user_tz": 300
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "c2271e55-05c2-4d59-d508-8fc9372f7083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Loading checkpoint models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [00:14<00:00, 14.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 2523546 tokens\n",
      "Training...\n",
      "[10 | 30.14] loss=2.93 avg=2.93\n",
      "[20 | 52.89] loss=3.05 avg=2.99\n",
      "[30 | 76.15] loss=2.88 avg=2.95\n",
      "[40 | 99.96] loss=3.17 avg=3.01\n",
      "[50 | 123.59] loss=2.91 avg=2.99\n",
      "[60 | 146.97] loss=2.86 avg=2.96\n",
      "[70 | 170.34] loss=2.72 avg=2.93\n",
      "[80 | 193.86] loss=3.04 avg=2.94\n",
      "[90 | 217.38] loss=2.93 avg=2.94\n",
      "[100 | 240.87] loss=2.72 avg=2.92\n",
      "[110 | 264.36] loss=2.86 avg=2.91\n",
      "[120 | 287.84] loss=2.84 avg=2.91\n",
      "[130 | 311.33] loss=3.01 avg=2.91\n",
      "[140 | 334.83] loss=3.01 avg=2.92\n",
      "[150 | 358.32] loss=2.63 avg=2.90\n",
      "[160 | 381.81] loss=2.74 avg=2.89\n",
      "[170 | 405.29] loss=2.85 avg=2.89\n",
      "[180 | 428.77] loss=2.78 avg=2.88\n",
      "[190 | 452.26] loss=2.66 avg=2.87\n",
      "[200 | 475.75] loss=2.92 avg=2.87\n",
      "======== SAMPLE 1 ========\n",
      " this is not acceptable\" because he \"has a lot of friends … [he] had a lot of times\" with Baskauskas during the campaign, the media outlet reported.\n",
      "\n",
      "In a statement to Reuters, Baskauskas said: \"The President is concerned and is responding to all calls. It is necessary to give the right message. I respect the President's judgment. There has been a lot of conversations between the members of our security cabinet, the members of our military, the President, and this should be done … there were no inappropriate conversations during the campaign. It is my understanding that these people were concerned over the fact that there was a conflict in Ukraine, as the media did, it has been very difficult to separate those concerns from the US position and our concerns over the Ukraine. It has been done.\"\n",
      "\n",
      "Trump and Ukrainian leader Volodymyr Zelensky have been vocal in their opposition to the Kremlin's Ukraine policy and the US-EU sanctions regime against Russia over its meddling in the 2016 race which led to the resignation of US President Donald Trump in January 2017.\n",
      "\n",
      "Trump has repeatedly been accused of interfering with the US election and the US president also repeatedly accused Ukrainian President Volodymyr Zelensky of having \"bad judgment\", with the Ukrainian leader accusing Trump of \"putting pressure on\" the Russian president in 2016.\n",
      "\n",
      "Earlier, Ukrainian defence spokesman Valentin Popov told reporters, that he would not comment on the US President and that the US President is \"not interested\".\n",
      "\n",
      "© AP Photo / Yaroslav Volkednik\n",
      "\n",
      "US President Donald Trump Says He'll Back Ukraine's Volodymyr Zelensky Amid Ukraine-US Rapprochement\n",
      "\n",
      "New Delhi (Sputnik): India has agreed to buy $17 billion in the Indian Army Group (IAG) for India’s proposed multi-role defence cooperation.\n",
      "\n",
      "A day after the Indian Defence Acquisition Mission (AFA) confirmed the acquisition of $17 billion — the largest purchase of the Army Group so far — the Indian Ministry of Defence said it had agreed to the sale of the group to the US and $17 billion to the US state as part of the agreement.\n",
      "\n",
      "— ANI (@ANI) October 27, 2019\n",
      "\n",
      "According to industry sources, the Indian Army Group will be used in the upcoming joint operations, while the Army will be used in the Indian Army's Rapid Response (RIP) operations.\n",
      "\n",
      "The AFA will be supported by the Indian Army's first and two third world combat teams and will cover India’s Army Rapid Response (RTP) and the Indian ArmyRapid Response (Rap) operations.\n",
      "\n",
      "The AFA will be delivered to the US ArmyRapid Response Team or ArmyRapid Response Team (AFRTC) in January 2019 to provide Indian Army forces with interoperability with the US ArmyRapid Response Team operational in Afghanistan and the Indian ArmyRapid Response Team's Operation Peace Spring in Pakistan.\n",
      "\n",
      "The Army Group will remain with the US Army Rap Team after the acquisition. AFA will be used in the ArmyRapid Response Team in Afghanistan as a part of the RTP missions, the sources said.\n",
      "\n",
      "The AFA will be used in the Indian Army's Rapid Response to ensure interoperability with existing ArmyRapid Response.\n",
      "\n",
      "A military source said that India had informed the US Army that the AFA would be transferred to the Army in January and that two companies of the ArmyRapid Response (ArmyRapid RT) and ArmyRapid RT (ArmyRapid AT) will be sent to Pakistan.\n",
      "\n",
      "Indian Army Group has already been deployed in the Indian Army's Rapid Response (RA) operations in Afghanistan and Pakistan.\n",
      "\n",
      "The Army Group was ordered to undergo a feasibility study for acquiring its own weapons system, a report said.\n",
      "\n",
      "The AFA is expected to be delivered in January 2019. But a year ago, the Indian Army Group agreed to acquire Javelin 5 missiles for $400 million; it got Javelin 5X missiles from China in October 2018 and India's Javelin 5X missiles from China in spring 2019.\n",
      "\n",
      "© AP Photo / Nirmala Sithar, File\n",
      "\n",
      "Narendra Modi, India’s Defence Minister, shows Indian Armed Forces Javelin-5 missiles when they test-fired their Javelin 5 missiles\n",
      "\n",
      "Indian Army will develop a “new” long-range medium-range missile system, a process which could be set up over the next two to three years for operational tests within India.\n",
      "\n",
      "India’s Defence Minister, who made a visit to Delhi in January this year, announced a new “New Delhi Defense Facility” in Delhi to be installed by the end of 2019.\n",
      "\n",
      "Indian Army had originally had a “New Delhi Defense Facility’ planned for the Indian Army on 31 October 2019. The Indian Army previously bought two weapons systems from China.\n",
      "\n",
      "US Defense Secretary John\n",
      "\n",
      "[210 | 510.97] loss=2.86 avg=2.87\n",
      "[220 | 534.46] loss=3.01 avg=2.88\n",
      "[230 | 557.93] loss=2.78 avg=2.87\n",
      "[240 | 581.37] loss=2.71 avg=2.87\n",
      "[250 | 604.88] loss=2.75 avg=2.86\n",
      "[260 | 628.41] loss=2.51 avg=2.85\n",
      "[270 | 651.90] loss=2.77 avg=2.84\n",
      "[280 | 675.39] loss=2.74 avg=2.84\n",
      "[290 | 698.89] loss=2.74 avg=2.83\n",
      "[300 | 722.38] loss=2.73 avg=2.83\n",
      "[310 | 745.87] loss=2.82 avg=2.83\n",
      "[320 | 769.38] loss=2.53 avg=2.82\n",
      "[330 | 792.93] loss=2.75 avg=2.82\n",
      "[340 | 816.41] loss=2.61 avg=2.81\n",
      "[350 | 839.90] loss=2.81 avg=2.81\n",
      "[360 | 863.45] loss=2.60 avg=2.80\n",
      "[370 | 886.98] loss=2.65 avg=2.80\n",
      "[380 | 910.48] loss=2.71 avg=2.79\n",
      "[390 | 933.97] loss=2.72 avg=2.79\n",
      "[400 | 957.45] loss=2.67 avg=2.79\n",
      "======== SAMPLE 1 ========\n",
      " Weapons to be released from the Joint Chiefs of Staff.\n",
      "\n",
      "© AP Photo/ Mark Wilson\n",
      "\n",
      "Army Chief of Staff, Army Gen. Mark Milley, speaks during a media briefing, Tuesday, June 23, 2019, in Washington.\n",
      "\n",
      "The statement comes after the White House issued a warning about Trump administration plans to release an additional batch of US military hardware to the Iraqi government this summer, and the Army has already begun carrying out tests of its own troops to ensure “maximum operational readiness”.\n",
      "\n",
      "On Tuesday, the Defence Department said that Iraqi forces had been preparing to complete the security offensive to clear the Iraqi city and allow the withdrawal of US troops, following the successful withdrawal from Mosul.\n",
      "\n",
      "Trump has also stated that he is “sad” that a deal with the Kurdish forces in exchange for Iraqi troops “keeping “the train and the ammunition in readiness,” and that he “could lose the oil,” the media reported. The US military chief also remarked that US military forces in Iraq were also planning “to leave for Syria,” the outlet reported.\n",
      "\n",
      "The Pentagon earlier confirmed that Iraqi forces had begun their withdrawal from Mosul, but on Tuesday stressed that Iraqi forces remain on the outskirts of the city. Iraqi Prime Minister Adel Abdul Mahdi has reportedly indicated that Mosul remains under an Iraqi siege that has only been lifted a day ago.\n",
      "\n",
      "The US is holding a military summit in Sochi, Russia, on Wednesday aimed at ending the standoff between Russia and Damascus.\n",
      "\n",
      "\"This is a very important summit,\" Kremlin spokesman Dmitry Peskov said. \"The US is holding a military summit. The aim is to end the confrontation between Russia and the Bashar Assad regime. I believe that the US President, on his way to the meeting, will give a clear message that Russia will never allow him to stay on the sidelines.\"\n",
      "\n",
      "© Sputnik / Aleksey Ulyukhin\n",
      "\n",
      "Russian Forces in Syria.\n",
      "\n",
      "The US has said that its involvement in the conflict must be stopped, and that Damascus has urged its allies to join the effort.\n",
      "\n",
      "\"The American military and the Syrian military partners have stated that this is the only solution, without political settlement, to the conflict between the two countries, and that Assad must assume that role, without US interference,\" White House spokesman said in a statement.\n",
      "\n",
      "Washington’s response to the incident on Tuesday appears to have been that it is not the US who is responsible. The statement also suggested that Syria's President may soon be seen as a “troublemaker” and a threat in order to further Washington’s aims.\n",
      "\n",
      "Ahead of the summit, the White House said that Washington did not want to disrupt it, and called it “a mistake”.\n",
      "\n",
      "\"The American president said he planned to meet with the Syrian president and to ask for a ceasefire. He did just one thing wrong ... He called the meeting a mistake, and he must apologize.\"\n",
      "\n",
      "\"He said he didn't intend to make a mistake. His actions and his words didn't go down well: He failed to fulfill his political mission, and he lost,\" White House said, adding that this would “disgust and frustration\" among US allies.\n",
      "\n",
      "Sputnik reported last week that the US and Saudi Arabia were threatening the alliance after Washington threatened to attack the Daesh* terror group in its vicinity if Iraq refused to accept an American raid on their oil fields, which was to last for seven days for $32 billion. Riyadh has repeatedly threatened to use its air power to attack the group, while the United States was allegedly planning to conduct the operation in retaliation for the bombing of Daesh* headquarters in Syria.\n",
      "\n",
      "The US State Department has warned on Tuesday that Washington would carry out “a strike” if Ankara’s air power failed and Turkey struck the oil and gas facilities.\n",
      "\n",
      "US Secretary of State Mike Pompeo said on Tuesday that Washington’s plan to impose sanctions on Syria would be the last before the end of the month.\n",
      "\n",
      "\"Syria needs to do the right thing. This is the only solution. And the only one that will come from Washington,\" Pompeo said, as quoted by Bloomberg.\n",
      "\n",
      "As the first round of negotiations between the government of former president Hafez Assad broke off on Tuesday, Assad, the leader of the opposition, spoke of having to leave the country and said that Washington had been doing it as a \"game changer.\"\n",
      "\n",
      "Assad asserted that Washington has been playing games with him since the start of 2018. \"And I tell every political opponent I know what I’re doing, and we can see it. They say if Bashar or Hadi were to join our side, he would join the side of Bashar Assad, and we do what we can do to stop that,\" Assad told reporters at the start of the talks.\n",
      "\n",
      "Assad stressed that Washington would be the only way\n",
      "\n",
      "[410 | 992.12] loss=2.56 avg=2.78\n",
      "[420 | 1015.62] loss=2.59 avg=2.78\n",
      "[430 | 1039.11] loss=2.55 avg=2.77\n",
      "[440 | 1062.65] loss=2.56 avg=2.76\n",
      "[450 | 1086.15] loss=2.63 avg=2.76\n",
      "[460 | 1109.64] loss=2.38 avg=2.75\n",
      "[470 | 1133.13] loss=2.82 avg=2.75\n",
      "[480 | 1156.61] loss=2.64 avg=2.75\n",
      "[490 | 1180.09] loss=2.65 avg=2.75\n",
      "[500 | 1203.58] loss=2.64 avg=2.74\n",
      "Saving checkpoint/run1/model-500\n",
      "[510 | 1229.90] loss=2.37 avg=2.73\n",
      "[520 | 1253.44] loss=2.72 avg=2.73\n",
      "[530 | 1276.94] loss=2.41 avg=2.73\n",
      "[540 | 1300.40] loss=2.51 avg=2.72\n",
      "[550 | 1323.88] loss=2.47 avg=2.72\n",
      "[560 | 1347.41] loss=2.80 avg=2.72\n",
      "[570 | 1370.94] loss=2.66 avg=2.72\n",
      "[580 | 1394.41] loss=2.53 avg=2.71\n",
      "[590 | 1417.90] loss=2.76 avg=2.71\n",
      "[600 | 1441.67] loss=2.67 avg=2.71\n",
      "======== SAMPLE 1 ========\n",
      "собр) Публикацию в Instagram\n",
      "\n",
      "It's not the first time that the country has been rocked by scandals. A string of scandals that took place during President Bill Clinton’s tenure led President Donald Trump to publicly call out the \"very people\" involved in the impeachment campaign, including his attorney general.\n",
      "\n",
      "The US president tweeted that the impeachment inquiry will be carried out against the Democratic Democratic Party.\n",
      "\n",
      "“I’m going to announce it. I will announce it this morning,\" Trump tweeted on Friday. \"If this is done, the Democratic party will say, 'Look, we really are done with this investigation. It’s now public. You can’t impeach me,” said Trump.\n",
      "\n",
      "I’m going to announce it. I will announce it this morning. @BarackObama pic.twitter.com/R5PQoQWbR8\n",
      "\n",
      "— Donald J. Trump (@realDonaldTrump) October 15, 2019\n",
      "\n",
      "“It’s not the first time.\"\n",
      "\n",
      "The US president lashed out at the Democratic leadership for their failure to take him up on his promises of not releasing his tax returns and of not releasing his birth record. Some Republicans accused Trump of being the person who made the illegal leak that he made to the media and the Democrat press and called him a “coup-e-joker”.\n",
      "\n",
      "Trump’s tirade against the Democratic leadership followed an email exchange in which Clinton expressed confidence about the impeachment probe from the White House and pointed out that the impeachment committee has a large number of investigations it would rather not look into, including those it’s looking into.\n",
      "\n",
      "\"I am not going to look into the impeachment, because that wouldn’t be the way the American people would vote on it,” Trump said, according to the transcript released by the White House late on Thursday. \"[POTUS] is very popular and I am popular and he enjoys having a small family and doing what he does best - and that’s watching over people in the political arena.\"\n",
      "\n",
      "“You know that I will look into any investigation that comes up into your campaign - including any investigative report. And so far it has never been a priority. It’s been, and it’s been a priority. And you know it's a real possibility,” concluded the president, who also accused Democratic leaders of \"keeping him in power\" and asked if “everyone knows” the Democrats had done so much to undermine the president, claiming that the impeachment inquiry did nothing to affect their plans to “make a comeback\".\n",
      "\n",
      "“I know the Democrats are keeping him in power. I know you heard me. If you keep him in power... I will keep you in power until the last Democratic power-broker can come up and take the case\", the president added.\n",
      "\n",
      "Trump also took aim at Democratic leaders, saying that they were “a bunch of losers,” and that they were losing more and more to Democrats. He described them as “failing the American people and giving them a reason to vote for Trump,” the president claimed.\n",
      "\n",
      "“There's a bunch of Dems who are losing ground. I don’t know what caused it but they gave it to the Democrats, what bothered them most is that they keep losing ground\", he added.\n",
      "\n",
      "“There’s nothing personal about me because in my view I don’t care for either the American people or you\", the president said, adding that a man like Clinton was \"the worst president ever\".\n",
      "\n",
      "A woman is to have a very happy birthday if she wishes to use public funds for an annual wedding.\n",
      "\n",
      "A New York City-area woman turned fashion designer turned fashion model has given her daughter a surprise birthday in which she turned her hair into a ball, while the other cheek was adorned with a golden tiara.\n",
      "\n",
      "Jessica Bielstein, who has been a regular at the GQ social media magazine for over a decade, told The Hollywood Reporter that she’s received many gifts this year. She described her birthday special being the “Pumpkins Dance”, saying she got a lot of them.\n",
      "\n",
      "“One of the gifts that I got was a red balloon\", Bielstein told the publication. “I was like ‘Cool’ - I am so excited to wear a red balloon.’'\n",
      "\n",
      "“The most exciting gifts we received were orange balloons which were filled with flowers, and also a golden tiara (“Pumpkins Dance”).”\n",
      "\n",
      "“As I was at the birthday party, people were having a great time [giving gifts], and they were dressed like normal people, and I was really happy\", she added\n",
      "\n",
      "[610 | 1476.40] loss=2.57 avg=2.71\n",
      "[620 | 1499.89] loss=2.69 avg=2.71\n",
      "[630 | 1523.39] loss=2.64 avg=2.71\n",
      "[640 | 1546.91] loss=2.55 avg=2.70\n",
      "[650 | 1570.43] loss=2.49 avg=2.70\n",
      "[660 | 1593.94] loss=2.49 avg=2.69\n",
      "[670 | 1617.35] loss=2.65 avg=2.69\n",
      "[680 | 1640.82] loss=2.54 avg=2.69\n",
      "[690 | 1664.37] loss=2.58 avg=2.69\n",
      "[700 | 1687.90] loss=2.39 avg=2.68\n",
      "[710 | 1711.34] loss=2.47 avg=2.68\n",
      "[720 | 1734.83] loss=2.90 avg=2.68\n",
      "[730 | 1758.38] loss=2.86 avg=2.69\n",
      "[740 | 1781.92] loss=2.61 avg=2.68\n",
      "[750 | 1805.49] loss=2.44 avg=2.68\n",
      "[760 | 1829.03] loss=2.31 avg=2.67\n",
      "[770 | 1852.51] loss=2.45 avg=2.67\n",
      "[780 | 1876.01] loss=2.50 avg=2.67\n",
      "[790 | 1899.50] loss=2.62 avg=2.66\n",
      "[800 | 1922.99] loss=2.32 avg=2.66\n",
      "======== SAMPLE 1 ========\n",
      " flashing your phone after you're out in public like a wild animal.\n",
      "\n",
      "As you can see I'm wearing a yellow jacket and I'm running all over the ground. You know this is happening to me. I'm scared. I'm begging the police to be quicker and I don't want it to happen again.\n",
      "\n",
      "— Brian Stearns (@brk_stearns) October 29, 2019\n",
      "\n",
      "​​The video's viral video sharing page claimed that the police had been called to the scene, and that a female suspect, named Laquan McDonald, was spotted chasing a white Toyota Camry driver that the police had not otherwise called. CCTV footage from the scene on several locations shows it was McDonald who then made a left hand turn to run away before being chased right into a wall. He was later killed by police.\n",
      "\n",
      "A woman who filmed the confrontation from a distance also shared her horror of the police chase.\n",
      "\n",
      "An elderly female friend is seen approaching the back of the Toyota Corolla as the cops start heading to the scene of the incident just moments after a cop was forced to rush to a nearby Walmart to arrest her in the street.\n",
      "\n",
      "Провоблика эка вотращикедел\n",
      "\n",
      "Публика быля домангульнаяли бото полет в‍ла бонев реКли. Поюдалио на всеркеть надоталитрает вредана. https://t.co/lZkJgR7hR9S pic.twitter.com/qM2lN1k8Dt\n",
      "\n",
      "— Rishai Bhatt (@RishaiK) October 29, 2019\n",
      "\n",
      "​One woman said she \"heard someone yell 'Get out! Get out! Get out!'\". The video was uploaded to a local Instagram account which apparently garnered thousands of likes and shares as well.\n",
      "\n",
      "The woman is seen running in the streets of London as officers and police continue to chase the driver, whose identity was not immediately released, while footage shot inside the car on the same footage continued to surface and circulate.\n",
      "\n",
      "The incident comes three days after German rapper BTSYX announced that his album YA was canceled due to his alleged \"sexual assault\" towards a woman.\n",
      "\n",
      "Russian rapper BTSYX has decided to end his label NWA Recordings and Holdings and cancel all official merch and concert merch from his upcoming album YA from his label NWA. In July, BTSYX said that a personal apology was \"more important\" than official merch.\n",
      "\n",
      "According to media reports, BTSYX is slated to make his first solo album in November following his previous statements on the matter, with the artist's new album YA due out on November 5.\n",
      "\n",
      "Earlier in June, the former X-Men and Teenage Mutant Ninja Turtles actor was caught on camera talking about his recent behavior toward a female actor, who had a relationship with him. Despite the singer saying that he has not said anything \"completely inappropriate,\" he did not comment on the footage.\n",
      "\n",
      "This week, the singer apologized to the woman who had worked with him since 2009, saying that his relationship with her is \"untrue\" and that it's time for him to take a break from his work.\n",
      "\n",
      "The musician said that he loves the relationship he has with women, and said he wanted to work with her \"more than once,\" while the woman was \"not real close to me.\" He added that \"she never offered anything to me, she never said anything to me, never said anything to anyone.\"\n",
      "\n",
      "The singer said in a new interview that he felt \"uninspired\" as a woman because he felt like that he was a \"coup artist.\"\n",
      "\n",
      "\"I always liked women. There was a time when women were just a commodity ... There was less than enough and more than enough,\" he shared.\n",
      "\n",
      "In the past few weeks, the former X-Men actor has shared a number of controversial remarks on the company, as he said that he was making his own music after leaving NWA.\n",
      "\n",
      "In June, BTSYX was spotted on the set of a new documentary for Vice. In it, he made comments that implied that it was time for him to \"get some time off.\"\n",
      "\n",
      "On 30 October, the German film giant Viacom filed for bankruptcy protection, saying that it would collapse. The company said that it had over 10 million employees and had been forced to suspend investments.\n",
      "\n",
      "MOSCOW (Sputnik) –\n",
      "\n",
      "[810 | 1957.54] loss=2.57 avg=2.66\n",
      "[820 | 1981.04] loss=2.55 avg=2.66\n",
      "[830 | 2004.54] loss=2.71 avg=2.66\n",
      "[840 | 2028.04] loss=2.47 avg=2.65\n",
      "[850 | 2051.54] loss=2.59 avg=2.65\n",
      "[860 | 2075.04] loss=2.58 avg=2.65\n",
      "[870 | 2098.54] loss=2.42 avg=2.65\n",
      "[880 | 2122.06] loss=2.36 avg=2.64\n",
      "[890 | 2145.56] loss=2.56 avg=2.64\n",
      "[900 | 2169.07] loss=2.47 avg=2.64\n",
      "[910 | 2192.55] loss=2.62 avg=2.64\n",
      "[920 | 2216.05] loss=2.55 avg=2.64\n",
      "[930 | 2239.53] loss=2.69 avg=2.64\n",
      "[940 | 2263.01] loss=2.32 avg=2.63\n",
      "[950 | 2286.50] loss=2.44 avg=2.63\n",
      "[960 | 2309.99] loss=2.47 avg=2.63\n",
      "[970 | 2333.49] loss=2.43 avg=2.62\n",
      "[980 | 2357.01] loss=2.51 avg=2.62\n",
      "[990 | 2380.52] loss=2.42 avg=2.62\n",
      "[1000 | 2403.97] loss=2.43 avg=2.61\n",
      "Saving checkpoint/run1/model-1000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.finetune(sess, \n",
    "              dataset=file_name,\n",
    "              model_name='124M',\n",
    "              steps=1000,\n",
    "              restore_from='fresh',\n",
    "              run_name='run1',\n",
    "              print_every=10,\n",
    "              sample_every=200,\n",
    "              save_every=500\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IXSuTNERaw6K"
   },
   "source": [
    "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
    "\n",
    "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VHdTL8NDbAh3"
   },
   "outputs": [],
   "source": [
    "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQJgV_b4bmzd"
   },
   "source": [
    "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pel-uBULXO2L"
   },
   "source": [
    "## Load a Trained Model Checkpoint\n",
    "\n",
    "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCcx5u7sbPTD"
   },
   "outputs": [],
   "source": [
    "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTa6zf3e_9gV"
   },
   "source": [
    "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
    "\n",
    "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12579,
     "status": "ok",
     "timestamp": 1581450994232,
     "user": {
      "displayName": "Barney Ales",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDMQ8dxB0YgPuHrb8rHWGEB249MalarcY7DpcE2=s64",
      "userId": "06512472277656029571"
     },
     "user_tz": 300
    },
    "id": "-fxL77nvAMAX",
    "outputId": "5011d854-d4a5-46fb-a1fb-65f9b6945005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint/run1/model-1000\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1000\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ClJwpF_ACONp"
   },
   "source": [
    "## Generate Text From The Trained Model\n",
    "\n",
    "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model.\n",
    "\n",
    "The below code creates a list of 150 randomly generated strings of token length 800 and saves them as a json file.  Note: token length roughly equates to word count, but since GPT-2 uses Byte Pair Encoding to create the tokens in its vocabulary, so tokens are usually parts of words.  For more info on tokenization read [the illustrated gpt-2](http://jalammar.github.io/illustrated-gpt2/).  Using a GPU powered Colab Notebook it takes roughly 13 seconds to generate each text string.  Since the generation process is lengthy and resource intensive text strings are best created in batches and then combined together, as Colab can run out of memory, idle timeout, or deactive your session, which all will crash your generation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2924
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8006347,
     "status": "ok",
     "timestamp": 1581462995255,
     "user": {
      "displayName": "Barney Ales",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDMQ8dxB0YgPuHrb8rHWGEB249MalarcY7DpcE2=s64",
      "userId": "06512472277656029571"
     },
     "user_tz": 300
    },
    "id": "4RNY6RBI9LmL",
    "outputId": "6d6f0df0-33ce-4987-ef13-75adce334c81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Round:  0\n",
      "Round:  1\n",
      "Round:  2\n",
      "Round:  3\n",
      "Round:  4\n",
      "Round:  5\n",
      "Round:  6\n",
      "Round:  7\n",
      "Round:  8\n",
      "Round:  9\n",
      "Round:  10\n",
      "Round:  11\n",
      "Round:  12\n",
      "Round:  13\n",
      "Round:  14\n",
      "Round:  15\n",
      "Round:  16\n",
      "Round:  17\n",
      "Round:  18\n",
      "Round:  19\n",
      "Round:  20\n",
      "Round:  21\n",
      "Round:  22\n",
      "Round:  23\n",
      "Round:  24\n",
      "Round:  25\n",
      "Round:  26\n",
      "Round:  27\n",
      "Round:  28\n",
      "Round:  29\n",
      "Round:  30\n",
      "Round:  31\n",
      "Round:  32\n",
      "Round:  33\n",
      "Round:  34\n",
      "Round:  35\n",
      "Round:  36\n",
      "Round:  37\n",
      "Round:  38\n",
      "Round:  39\n",
      "Round:  40\n",
      "Round:  41\n",
      "Round:  42\n",
      "Round:  43\n",
      "Round:  44\n",
      "Round:  45\n",
      "Round:  46\n",
      "Round:  47\n",
      "Round:  48\n",
      "Round:  49\n",
      "Round:  50\n",
      "Round:  51\n",
      "Round:  52\n",
      "Round:  53\n",
      "Round:  54\n",
      "Round:  55\n",
      "Round:  56\n",
      "Round:  57\n",
      "Round:  58\n",
      "Round:  59\n",
      "Round:  60\n",
      "Round:  61\n",
      "Round:  62\n",
      "Round:  63\n",
      "Round:  64\n",
      "Round:  65\n",
      "Round:  66\n",
      "Round:  67\n",
      "Round:  68\n",
      "Round:  69\n",
      "Round:  70\n",
      "Round:  71\n",
      "Round:  72\n",
      "Round:  73\n",
      "Round:  74\n",
      "Round:  75\n",
      "Round:  76\n",
      "Round:  77\n",
      "Round:  78\n",
      "Round:  79\n",
      "Round:  80\n",
      "Round:  81\n",
      "Round:  82\n",
      "Round:  83\n",
      "Round:  84\n",
      "Round:  85\n",
      "Round:  86\n",
      "Round:  87\n",
      "Round:  88\n",
      "Round:  89\n",
      "Round:  90\n",
      "Round:  91\n",
      "Round:  92\n",
      "Round:  93\n",
      "Round:  94\n",
      "Round:  95\n",
      "Round:  96\n",
      "Round:  97\n",
      "Round:  98\n",
      "Round:  99\n",
      "Round:  100\n",
      "Round:  101\n",
      "Round:  102\n",
      "Round:  103\n",
      "Round:  104\n",
      "Round:  105\n",
      "Round:  106\n",
      "Round:  107\n",
      "Round:  108\n",
      "Round:  109\n",
      "Round:  110\n",
      "Round:  111\n",
      "Round:  112\n",
      "Round:  113\n",
      "Round:  114\n",
      "Round:  115\n",
      "Round:  116\n",
      "Round:  117\n",
      "Round:  118\n",
      "Round:  119\n",
      "Round:  120\n",
      "Round:  121\n",
      "Round:  122\n",
      "Round:  123\n",
      "Round:  124\n",
      "Round:  125\n",
      "Round:  126\n",
      "Round:  127\n",
      "Round:  128\n",
      "Round:  129\n",
      "Round:  130\n",
      "Round:  131\n",
      "Round:  132\n",
      "Round:  133\n",
      "Round:  134\n",
      "Round:  135\n",
      "Round:  136\n",
      "Round:  137\n",
      "Round:  138\n",
      "Round:  139\n",
      "Round:  140\n",
      "Round:  141\n",
      "Round:  142\n",
      "Round:  143\n",
      "Round:  144\n",
      "Round:  145\n",
      "Round:  146\n",
      "Round:  147\n",
      "Round:  148\n",
      "Round:  149\n",
      "/content/drive/My Drive/Colab Notebooks\n",
      "\u001b[0m\u001b[01;34m'698R - Data Science Math'\u001b[0m/\n",
      " \u001b[01;34mcheckpoint\u001b[0m/\n",
      "'Copy of Train a GPT-2 Text-Generating Model w  GPU'\n",
      " Data_Science_Mathematics_Session_2-ALES.ipynb\n",
      " English_Language-State_Controlled_Media-11-2019.csv\n",
      " gpt_sputnik_text_data_2.json\n",
      " gpt_sputnik_text_data_3.json\n",
      " gpt_sputnik_text_data_4.json\n",
      " gpt_sputnik_text_data_5.json\n",
      " gpt_sputnik_text_data_6.json\n",
      " gpt_sputnik_text_data.json\n",
      " markovify_text_stored.json\n",
      " \u001b[01;34mMST698O-Intro_Data_Science\u001b[0m/\n",
      " \u001b[01;34mMST698R-Data_Science_Math\u001b[0m/\n",
      " MST-698R_Project_Ales.ipynb\n",
      " MST-698R_Project_Analysis-ALES.ipynb\n",
      " Research_Notes.ipynb\n",
      " Sputnik_body_alltext.p\n",
      " \u001b[01;34mThesis\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "gpt_text_stored = []\n",
    "for n in range(0, 150):\n",
    "    print(\"Round: \", str(n))\n",
    "    gpt_text_stored.append(gpt2.generate(sess, run_name='run1', length=800, return_as_list=True)[0])\n",
    "\n",
    "%cd /content/drive/'My Drive'/'Colab Notebooks'\n",
    "with open('gpt_sputnik_text_data_6.json', 'w', encoding='utf-8') as f:\n",
    "   json.dump(gpt_text_stored, f, ensure_ascii=False, indent=4)\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oF4-PqF0Fl7R"
   },
   "source": [
    "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
    "\n",
    "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
    "\n",
    "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
    "\n",
    "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
    "\n",
    "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
    "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
    "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
    "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
    "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
    "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ig-KVgkCDCKD"
   },
   "source": [
    "# Etcetera\n",
    "\n",
    "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rIHiVP53FnsX"
   },
   "outputs": [],
   "source": [
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmTXWNUygS5E"
   },
   "source": [
    "# LICENSE\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2019 Max Woolf\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Train a GPT-2 Text-Generating Model w/ GPU",
   "provenance": [
    {
     "file_id": "1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce",
     "timestamp": 1580388492123
    },
    {
     "file_id": "1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK",
     "timestamp": 1555602712120
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
